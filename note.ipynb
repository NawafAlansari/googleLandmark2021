{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nma5214/anaconda3/envs/googleLandMark/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "# Utils\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "g_ = Fore.GREEN\n",
    "c_ = Fore.CYAN\n",
    "b_ = Fore.BLUE\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure W&B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnma5214\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"../data/googleLandmarkRetrieval/\"\n",
    "TRAIN_DIR = \"../data/googleLandmarkRetrieval/train/\"\n",
    "TEST_DIR = \"../data/googleLandmarkRetrieval/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = dict(\n",
    "    seed = 42, \n",
    "    model_name = \"tf_mobilenetv3_small_100\", \n",
    "    train_batch_size = 1, \n",
    "    valid_batch_size = 1, \n",
    "    img_size = 224, \n",
    "    epochs = 3, \n",
    "    learning_rate = 5e-4, \n",
    "    scheduler = None, \n",
    "    weight_decay = 1e-6, \n",
    "    n_accumulate = 1, \n",
    "    n_folds = 5, \n",
    "    num_classes = 81313, \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"), \n",
    "    competition = \"GOOGL\", \n",
    "    _wandb_kernel = \"deb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Random Seeds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42): \n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    torch.backends.cudnn.benchmark = True \n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "set_seed(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_path(id):\n",
    "    return f\"{TRAIN_DIR}/{id[0]}/{id[1]}/{id[2]}/{id}.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{ROOT_DIR}/train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df.landmark_id = le.fit_transform(df.landmark_id)\n",
    "joblib.dump(le, \"label_encoder.pkl\")\n",
    "\n",
    "df['file_path'] = df['id'].apply(get_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17660ef415d37059</td>\n",
       "      <td>0</td>\n",
       "      <td>../data/googleLandmarkRetrieval/train//1/7/6/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92b6290d571448f6</td>\n",
       "      <td>0</td>\n",
       "      <td>../data/googleLandmarkRetrieval/train//9/2/b/9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cd41bf948edc0340</td>\n",
       "      <td>0</td>\n",
       "      <td>../data/googleLandmarkRetrieval/train//c/d/4/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fb09f1e98c6d2f70</td>\n",
       "      <td>0</td>\n",
       "      <td>../data/googleLandmarkRetrieval/train//f/b/0/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25c9dfc7ea69838d</td>\n",
       "      <td>1</td>\n",
       "      <td>../data/googleLandmarkRetrieval/train//2/5/c/2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  landmark_id  \\\n",
       "0  17660ef415d37059            0   \n",
       "1  92b6290d571448f6            0   \n",
       "2  cd41bf948edc0340            0   \n",
       "3  fb09f1e98c6d2f70            0   \n",
       "4  25c9dfc7ea69838d            1   \n",
       "\n",
       "                                           file_path  \n",
       "0  ../data/googleLandmarkRetrieval/train//1/7/6/1...  \n",
       "1  ../data/googleLandmarkRetrieval/train//9/2/b/9...  \n",
       "2  ../data/googleLandmarkRetrieval/train//c/d/4/c...  \n",
       "3  ../data/googleLandmarkRetrieval/train//f/b/0/f...  \n",
       "4  ../data/googleLandmarkRetrieval/train//2/5/c/2...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nma5214/.vscodeProjects/kaggle_competitions/googleLandMarkRetrival2021/wandb/run-20220906_191620-2cdvm8ah</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nma5214/GLRet2021/runs/2cdvm8ah\" target=\"_blank\">happy-cloud-1</a></strong> to <a href=\"https://wandb.ai/nma5214/GLRet2021\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project='GLRet2021', \n",
    "                    config=CONFIG, \n",
    "                    job_type=\"Visualization\", \n",
    "                    anonymous='must')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [04:57<00:00, 10.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">happy-cloud-1</strong>: <a href=\"https://wandb.ai/nma5214/GLRet2021/runs/2cdvm8ah\" target=\"_blank\">https://wandb.ai/nma5214/GLRet2021/runs/2cdvm8ah</a><br/>Synced 6 W&B file(s), 1 media file(s), 3001 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220906_191620-2cdvm8ah/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from re import L\n",
    "\n",
    "\n",
    "preview_table = wandb.Table(columns=['Id', 'Image', 'Landmark ID'])\n",
    "tmp_df = df.sample(3000, random_state=CONFIG['seed']).reset_index(drop=True)\n",
    "\n",
    "for i in tqdm(range(len(tmp_df))):\n",
    "    row = tmp_df.loc[i]\n",
    "    img = Image.open(row.file_path)\n",
    "    preview_table.add_data(row.id, wandb.Image(img), row.landmark_id)\n",
    "\n",
    "wandb.log({\"Visualization\": preview_table})\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.4, stratify=df.landmark_id, shuffle=True, random_state=CONFIG['seed'])\n",
    "\n",
    "df_valid, df_test = train_test_split(df_test, test_size=0.5, shuffle=True, random_state=CONFIG['seed'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1580470, 3), (948282, 3), (316094, 3), (316094, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df_train.shape, df_valid.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarkDataset(Dataset):\n",
    "    def __init__(self, root_dir, df, transforms=None) -> None:\n",
    "        super().__init__()\n",
    "        self.root_dir = root_dir\n",
    "        self.df = df \n",
    "        self.file_names = df[\"file_path\"].values\n",
    "        self.labels = df['landmark_id'].values \n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "            img_path = self.file_names[index]\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            label = self.labels[index]\n",
    "\n",
    "            if self.transforms:\n",
    "                img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "            return img, label "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(CONFIG[\"img_size\"], CONFIG[\"img_size\"]), \n",
    "        A.HorizontalFlip(p=.5), \n",
    "        A.CoarseDropout(p=.5), \n",
    "        A.Normalize(max_pixel_value=255.0, p=1.0), \n",
    "        ToTensorV2()\n",
    "    ], p=1.), \n",
    "\n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(CONFIG[\"img_size\"], CONFIG[\"img_size\"]), \n",
    "        A.Normalize(max_pixel_value=255.0, p=1.0), \n",
    "        ToTensorV2()\n",
    "    ], p=1.)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LandmarkRetrievalModel(\n",
       "  (model): MobileNetV3(\n",
       "    (conv_stem): Conv2dSame(3, 16, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn1): BatchNormAct2d(\n",
       "      16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "      (drop): Identity()\n",
       "      (act): Hardswish()\n",
       "    )\n",
       "    (blocks): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): DepthwiseSeparableConv(\n",
       "          (conv_dw): Conv2dSame(16, 16, kernel_size=(3, 3), stride=(2, 2), groups=16, bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            72, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2dSame(72, 72, kernel_size=(3, 3), stride=(2, 2), groups=72, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            72, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv_dw): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): Identity()\n",
       "          (conv_pwl): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2dSame(96, 96, kernel_size=(5, 5), stride=(2, 2), groups=96, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): InvertedResidual(\n",
       "          (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2dSame(288, 288, kernel_size=(5, 5), stride=(2, 2), groups=288, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (bn2): BatchNormAct2d(\n",
       "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (se): SqueezeExcite(\n",
       "            (conv_reduce): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act1): ReLU(inplace=True)\n",
       "            (conv_expand): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (gate): Hardsigmoid()\n",
       "          )\n",
       "          (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNormAct2d(\n",
       "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): ConvBnAct(\n",
       "          (conv): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNormAct2d(\n",
       "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "            (drop): Identity()\n",
       "            (act): Hardswish()\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
       "    (conv_head): Conv2d(576, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (act2): Hardswish()\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (classifier): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=81313, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LandmarkRetrievalModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True) -> None:\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        self.n_features = self.model.classifier.in_features\n",
    "        self.model.reset_classifier(0)\n",
    "        self.fc = nn.Linear(self.n_features, CONFIG[\"num_classes\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.model(x)\n",
    "        output = self.fc(features)\n",
    "        return output \n",
    "\n",
    "    def extract_features(self, x):\n",
    "        features = self.model(x)\n",
    "        return features\n",
    "\n",
    "model = LandmarkRetrievalModel(CONFIG[\"model_name\"])\n",
    "model.to(CONFIG['device'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, targets):\n",
    "    return nn.CrossEntropyLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()\n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0 \n",
    "\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "\n",
    "    for step, (images, labels) in bar: \n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        with amp.autocast(enabled=True):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss / CONFIG[\"n_accumulate\"]\n",
    "\n",
    "        scaler.scale(loss).backward() \n",
    "\n",
    "        if (step + 1) % CONFIG[\"n_accumulate\"] == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            for p in model.parameters():\n",
    "                p.grad = None \n",
    "\n",
    "            \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss, LR=optimizer.param_groups[0][\"lr\"])\n",
    "    \n",
    "    gc.collect() \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    dataset_size = 0 \n",
    "    running_loss = 0.0 \n",
    "\n",
    "    TARGETS = [] \n",
    "    PREDS = [] \n",
    "\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "\n",
    "    for step, (images, labels) in bar:\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        PREDS.appends(preds.view(-1).cpu().detach().numpy())\n",
    "        TARGETS.append(labels.view(-1).cpu().detach().numpy())\n",
    "\n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss)\n",
    "\n",
    "        TARGETS = np.concatenate(TARGETS)\n",
    "        PREDS = np.concatenate(PREDS)\n",
    "        val_acc = accuracy_score(TARGETS, PREDS)\n",
    "        gc.collect() \n",
    "\n",
    "        return epoch_loss, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, optimizier, scheduelr,\n",
    "                train_dataloader,\n",
    "                val_dataloader,\n",
    "                device,\n",
    "                num_epochs, \n",
    "                run):\n",
    "\n",
    "    wandb.watch(model, log_freq=100)\n",
    "\n",
    "    if torch.cuda.is_available:\n",
    "        print(f\"[INFO] using GPU: {torch.cuda.get_device_name()}\\n\")\n",
    "\n",
    "        start = time.time() \n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        best_epoch_acc = 0 \n",
    "        history = defaultdict(list)\n",
    "\n",
    "        for epoch in range(1, num_epochs+1):\n",
    "            gc.collect() \n",
    "            train_epoch_loss = train_one_epoch(model, optimizier, scheduelr,\n",
    "                                                dataloader=train_dataloader,\n",
    "                                                device=CONFIG[\"device\"],\n",
    "                                                epoch=epoch )\n",
    "\n",
    "            val_epoch_loss, val_epoch_acc = valid_one_epoch(model,\n",
    "                                            dataloader=val_dataloader, \n",
    "                                            device=CONFIG[\"device\"], \n",
    "                                            epoch=epoch)\n",
    "\n",
    "            history[\"Train_Loss\"].append(train_epoch_loss)\n",
    "            history[\"Valid_Loss\"].append(val_epoch_loss)\n",
    "            history[\"Valid_acc\"].append(val_epoch_acc)\n",
    "\n",
    "            wandb.log({\"Train Loss\": train_epoch_loss})\n",
    "            wandb.log({\"Valid Loss\": val_epoch_loss})\n",
    "            wandb.log({\"Valid Acc\": val_epoch_acc})\n",
    "\n",
    "            print(f\"Valid Acc: {val_epoch_acc}\")\n",
    "\n",
    "            if val_epoch_acc >= best_epoch_acc: \n",
    "                print(f\"{c_}Validation Acc Improved ({best_epoch_acc} ---> {val_epoch_acc})\")\n",
    "                best_epoch_acc = val_epoch_acc\n",
    "                run.summary[\"Best Accuracy\"] = best_epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                PATH = \"ACC{:.4f}_epoch{:.0f}.bin\".format(best_epoch_acc, epoch)\n",
    "                torch.save(model.state_dict(), PATH)\n",
    "                wandb.save(PATH)\n",
    "                print(f\"Model Save{sr_}\")\n",
    "            \n",
    "            print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start \n",
    "\n",
    "    print(\"Trainign Complete in {:.0f}h {:.f}m {:.0f}s\".format(time_elapsed//3600, (time_elapsed%3600)//60, (time_elapsed%3600)%60))\n",
    "\n",
    "    print(\"Best ACC: {:.4f}\".format(best_epoch_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders():    \n",
    "    train_dataset = LandmarkDataset(TRAIN_DIR, df_train, transforms=data_transforms['train'])\n",
    "    valid_dataset = LandmarkDataset(TRAIN_DIR, df_valid, transforms=data_transforms['valid'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n",
    "                              num_workers=4, shuffle=True, pin_memory=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n",
    "                              num_workers=4, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader\n",
    "\n",
    "train_dataloder, valid_dataloader = prepare_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['T_max'], \n",
    "                                                   eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CONFIG['T_0'], \n",
    "                                                             T_mult=1, eta_min=CONFIG['min_lr'])\n",
    "    elif CONFIG['scheduler'] == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
    "scheduler = fetch_scheduler(optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nma5214/.vscodeProjects/kaggle_competitions/googleLandMarkRetrival2021/wandb/run-20220907_120823-3q04ix71</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nma5214/GLRet2021/runs/3q04ix71\" target=\"_blank\">royal-sun-8</a></strong> to <a href=\"https://wandb.ai/nma5214/GLRet2021\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project='GLRet2021', \n",
    "                 config=CONFIG,\n",
    "                 job_type='Train',\n",
    "                 anonymous='must')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] using GPU: NVIDIA GeForce GTX 970\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                               | 1199/948282 [04:37<57:06:22,  4.61it/s, Epoch=1, LR=0.0005, Train_Loss=11.3]"
     ]
    }
   ],
   "source": [
    "model, history = run_training(model, optimizer, \n",
    "                            scheduler,\n",
    "                            train_dataloder,\n",
    "                            valid_dataloader, \n",
    "                            CONFIG[\"device\"],\n",
    "                            CONFIG[\"epochs\"], \n",
    "                            run)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:googleLandMark]",
   "language": "python",
   "name": "conda-env-googleLandMark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d80e1c481a785ecdd31dffeb6d5d3fc1a37e8892266a47e7c05e10a363722bd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
